

from transformers import RobertaTokenizer
from collections import Counter
import math
from tqdm import tqdm
import pickle
import json


tokenizer = RobertaTokenizer.from_pretrained("Salesforce/codet5-base")

splits = ['train', 'validation', 'test']

splits = ['train', 'validation', 'test']

all_targets= []
for split in splits:

    file_path = './dataset/'+split+'_set.json'
    with open(file_path, 'r') as f:
        # all_targets.extend( f.readlines() )
        all_targets.extend(json.load(f))

new_all_targets, seen = [],[]
for l in all_targets:
    if l['commit_id'] not in seen:
        new_all_targets.append(l['cwe_list'])
        seen.append(l['commit_id'])

vocab = Counter(new_all_targets)
vocab_tokens = [i[0] for i in vocab.most_common(len(vocab))]
vocab_samples = [i[1] for i in vocab.most_common(len(vocab))]
vocab_score = [ 1/math.sqrt(n) for n in vocab_samples]
top_total = sum(i[1] for i in vocab.most_common(len(vocab)))
class_freq_dict = dict(vocab)
with open('./data/class_freq_file.pkl', 'wb') as f:
    pickle.dump(class_freq_dict, f)

